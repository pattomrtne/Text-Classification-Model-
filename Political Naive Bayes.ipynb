{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "# from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"/Users/patriciomartinez/Downloads/2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conventions',)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all tables in the database\n",
    "tables = convention_cur.execute(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    ").fetchall()\n",
    "\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "    '''\n",
    "    SELECT text, party\n",
    "    FROM conventions\n",
    "    '''\n",
    ")\n",
    "\n",
    "stopset = set(stopwords.words(\"english\"))\n",
    "\n",
    "def clean_tokenize(text):\n",
    "    text = text.lower()\n",
    "    for p in string.punctuation:\n",
    "        text = text.replace(p, \" \")\n",
    "    tokens = text.split()\n",
    "    return [t for t in tokens if t not in stopset and t.strip()]\n",
    "\n",
    "for row in query_results:\n",
    "    raw_text = row[0]\n",
    "    party    = row[1]\n",
    "    tokens   = clean_tokenize(raw_text)\n",
    "    cleaned  = \" \".join(tokens)\n",
    "    convention_data.append([cleaned, party])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tougaloo college reflects progression people slavery citizenship scholarship leadership contributing mississippi world alumni leaders like convention chairman congressman bennie thompson joe biden wants invest 70 billion hbcus like tougaloo imagine impact hbcus imagine impact hbcus could america mississippi cast 2 votes bernie sanders 38 votes next president joe biden',\n",
       "  'Democratic'],\n",
       " ['could happen remi gideon 00 01 40 52 lebanon proud mother three children remi 01 40 57 speaks english arabic french earned degree psychology words could figure works daycare teacher virginia remi 01 41 10 says feel blessed loyal citizen greatest country world country given opportunity lifetime realize potential dreams remi 01 41 20 congratulations that’s really great thank',\n",
       "  'Republican'],\n",
       " ['democracy beautiful', 'Democratic'],\n",
       " ['look across aisle see party wants pursue dreams see democrat party wants dictate dreams don’t see party wants free see party wants chain conformity destroy anyone deem heretic swore oath defend country constitution president trump sworn that’s he’s advanced freedom despite savage political attacks overcome agenda radical left president trump unleashed economic might nation like president history triggered rising tide working families brought us energy independence reclaimed jobs overseas democrats said would never return fiercely defended besieged first second amendment start',\n",
       "  'Republican'],\n",
       " ['racist coward … speaker 92 01 37 49 call … cops … speaker 93 01 37 49 going kill … speaker 94 01 37 49 i’m rape … speaker 95 01 37 58 mark mccloskey says family threatened violence',\n",
       "  'Republican'],\n",
       " ['yeah', 'Democratic'],\n",
       " ['maryland… bianca shah 01 13 07 home frederick douglass… brandon scott 01 13 09 …cast 1 vote bernie sanders 119 votes next president joe biden',\n",
       "  'Democratic'],\n",
       " ['i’m congressman matt gaetz i’m speaking auditorium emptier joe biden’s daily schedule nation full hearts clear minds see choice clearly strength weakness energy confusion success failure president trump first president since reagan start new war biden foolishly cheerled decades war without winning without end president trump knows strongest fight hardest distant deserts fellow americans must fight save america may lose forever joe biden might even notice settle biden that’s hashtag promoted aoc socialists woketopians settle biden make extra movie written produced directed others it’s horror film really they’ll disarm empty prisons lock home invite ms 13 live next door',\n",
       "  'Republican'],\n",
       " ['kayla wanted make home still working find god willing bring home kayla born miracle told would never second child god gave us kayla gave world eight months kayla’s captivity another hostage smuggle letter kayla written read could see god holding arms words felt tenderly cradled freefall also wrote “i shown darkness light learned even prison one free grateful many hours think absence finally 25 years old come realize place life none us could known would long know also fighting side ways able lot fight left inside breaking give matter long takes ” marcia mueller 01 22 43 kayla taught many things mom she’s still teaching us carl support donald trump commitment make keep america great power government passion people like kayla americans even darkest days always fight left inside americans don’t talk act daughter that’s president trump long stay strong like kayla long refuse break great thank',\n",
       "  'Republican'],\n",
       " ['joe biden’s america radical left get whatever want get pay they’ve already taken joe biden democratic party don’t let take america',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2435 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    ret_dict = dict()\n",
    "    for word in text.split():\n",
    "        if word in fw:\n",
    "            ret_dict[word] = True\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.494\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     25.8 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     14.9 : 1.0\n",
      "                 defense = True           Republ : Democr =     14.0 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "I notice that the “most informative” features list tells us which words are especially strong indicators for one party or the other. Whenever a speech includes the word \"china\", the model is about 26 times more likely to guess “Republican,” whereas the word \"votes\" makes it about 24 times more likely to predict “Democratic.” In general, words like \"enforcement\", \"destroy\", \"freedoms\", and \"defense\" tend to point toward Republicans, while \"climate\" and \"votes\" point toward Democrats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"/Users/patriciomartinez/Downloads/congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "\n",
    "for candidate, party, tweet in results:\n",
    "    cleaned_text = tweet.lower()\n",
    "    tweet_data.append([cleaned_text, party])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: b'earlier today, i spoke on the house floor abt protecting health care for women and praised @ppmarmonte for their work on the central coast. https://t.co/wqgtrzt7vv'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'go tribe! #rallytogether https://t.co/0nxutfl9l5'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b\"apparently, trump thinks it's just too easy for students overwhelmed by the crushing burden of debt to pay off student loans #trumpbudget https://t.co/ckyqo5t0qh\"\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'we\\xe2\\x80\\x99re grateful for our first responders, our rescue personnel, our firefighters, our police, and volunteers who have been working tirelessly to keep people safe, provide much-needed help, while putting their own lives on the line.\\n\\nhttps://t.co/ezpv0vmiz3'\n",
      "Actual party is Republican and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'let\\xe2\\x80\\x99s make it even greater !! #kag \\xf0\\x9f\\x87\\xba\\xf0\\x9f\\x87\\xb8 https://t.co/y9qozd5l2z'\n",
      "Actual party is Republican and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b\"we have about 1hr until the @cavs tie up the series 2-2. i'm #allin216 @repbarbaralee you scared? #roadtovictory\"\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'congrats to @belliottsd on his new gig at sd city hall. we are glad you will continue to serve\\xe2\\x80\\xa6 https://t.co/fkvmw3cqdi'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'we are really close, we have over $3500 raised toward the match right now. whoot!! (that\\xe2\\x80\\x99s $7000 for the non-math majors in the room \\xf0\\x9f\\x98\\x82). help us get there https://t.co/tu34c472sd https://t.co/qsdqkypsmc'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'today, the comment period for @potus\\xe2\\x80\\x99s plan to expand offshore drilling opened to the public. you have 60 days (until march 9) to share why you oppose the proposed program directly with the trump administration. comments can be made by email or mail. https://t.co/baaymejxqn'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'celebrated @icseastla\\xe2\\x80\\x99s 22 years of eastside commitment &amp; saluted community leaders at last night\\xe2\\x80\\x99s awards dinner! https://t.co/7v7gh8givb'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample :\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    features = conv_features(tweet, feature_words)\n",
    "    estimated_party = classifier.classify(features)\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    features = conv_features(tweet, feature_words)\n",
    "    estimated_party = classifier.classify(features)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 0, 'Democratic': 4278}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 0, 'Democratic': 5724})})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "The Naive Bayes model defaults to labeling virtually all tweets as Democratic in the sample, every Republican tweet was misclassified because the policy‐focused vocabulary learned from convention speeches doesn’t transfer to the informal, hashtag‐driven language of tweets. With features drawn from speeches, there’s almost no signal that a tweet is Republican, so the classifier collapses to one class. This highlights the domain mismatch and how relying solely on convention speech tokens fails when analyzing everyday tweets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
